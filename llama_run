from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import json
import re

BLUE = "\033[94m"
GREEN = "\033[92m"
RESET = "\033[0m"
MODEL_NAME = "microsoft/phi-3-mini-4k-instruct"
#MODEL_NAME = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16,
    device_map="auto" 
)

def generate_strict_json_response(user_text):
 
    prompt = f"""<s>[INST] <<SYS>>
You are a strict JSON generator. Classify this input as either:
{{"intent": "DOCUMENT_RETRIEVAL"}} or {{"intent": "CONVERSATION"}} based on user input intent.

Examples:
- Input": "Show my test results"
  Response: {{"intent": "DOCUMENT_RETRIEVAL"}}
- Input: "Hello"  
  Response: {{"intent": "CONVERSATION"}}
- Input: "Where's my lab report?"
  Response:	{{"intent": "DOCUMENT_RETRIEVAL"}}
- Input: "Tell me a joke"
  Response:{{"intent": "CONVERSATION"}}
- Input: "MRI results from last week"
  Response:{{"intent": "DOCUMENT_RETRIEVAL"}}

<</SYS>>

Input: "{user_text}"
Response: {{"intent": " [/INST]"""

    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    
    output = model.generate(
        **inputs,
        max_new_tokens=15,  
        temperature=0.01,  
        do_sample=False,
        pad_token_id=tokenizer.eos_token_id,
        num_return_sequences=1
    )
    
    full_text = tokenizer.decode(output[0], skip_special_tokens=True)
    json_str = "{\"intent\": \"" + full_text.split("{\"intent\": \"")[-1] 
    
    try:
        return json.loads(json_str.split("}")[0] + "}")  
    except json.JSONDecodeError:
        return {"intent": "CONVERSATION"}  

def chat_loop():
    print("Chat with me! Type 'quit' to exit.")
    while True:
        user_input = input(f"{BLUE}You: {RESET}").strip()
        if user_input.lower() == "quit":
            break
            
        response = generate_strict_json_response(user_input)
        print(f"{GREEN}Bot: {response}{RESET}")

if __name__ == "__main__":
    chat_loop()